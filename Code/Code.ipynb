{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#@title Imports and seeds\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport sys\nimport os\nimport random\nimport numpy as np\nimport time\nimport math\n\nseed = 69420\n\n\n# https://pytorch.org/docs/stable/notes/randomness.html\nrandom.seed(seed)\nnp.random.seed(seed)\n\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\ncudnn.benchmark = False\ncudnn.deterministic = True # it might cause runtime errors on certain operations\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n","metadata":{"papermill":{"duration":2.67582,"end_time":"2023-04-27T20:48:06.918871","exception":false,"start_time":"2023-04-27T20:48:04.243051","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-28T17:43:29.543911Z","iopub.execute_input":"2023-04-28T17:43:29.545037Z","iopub.status.idle":"2023-04-28T17:43:32.494366Z","shell.execute_reply.started":"2023-04-28T17:43:29.544987Z","shell.execute_reply":"2023-04-28T17:43:32.493315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! python --version","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:48:06.929146Z","iopub.status.busy":"2023-04-27T20:48:06.927942Z","iopub.status.idle":"2023-04-27T20:48:07.869365Z","shell.execute_reply":"2023-04-27T20:48:07.868163Z"},"papermill":{"duration":0.94865,"end_time":"2023-04-27T20:48:07.871841","exception":false,"start_time":"2023-04-27T20:48:06.923191","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install avalanche-lib==0.3.1","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:48:07.880771Z","iopub.status.busy":"2023-04-27T20:48:07.879712Z","iopub.status.idle":"2023-04-27T20:48:32.541019Z","shell.execute_reply":"2023-04-27T20:48:32.539691Z"},"papermill":{"duration":24.668488,"end_time":"2023-04-27T20:48:32.543749","exception":false,"start_time":"2023-04-27T20:48:07.875261","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Train and test loops\n\n\ndef train(network, optimizer, loss_fn, data_loader, device):\n    train_loss = 0.0\n    num_batches = 0\n    total_predictions = 0\n    correct_predictions = 0\n\n    network.train()\n    network.zero_grad()\n    for batch, labels, task_indices in data_loader:\n        batch, labels = batch.to(device), labels.to(device)\n\n        outputs = network(batch)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n\n        optimizer.step()\n        network.zero_grad()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n\n        total_predictions += labels.size(0)\n        correct_predictions += predicted.eq(labels).sum().item()\n        num_batches += 1\n  \n    return train_loss / num_batches, correct_predictions / total_predictions\n\ndef test(network, loss_fn, data_loader, device, return_confusion_matrix=False):\n    test_loss = 0.0\n    num_batches = 0\n    total_predictions = 0\n    correct_predictions = 0\n\n    confusion_matrix = [[0 for _ in range(11)] for _ in range(11)]\n\n    network.eval()\n    with torch.no_grad():\n        for batch, labels, task_indices in data_loader:\n            batch, labels = batch.to(device), labels.to(device)\n      \n            outputs = network(batch)\n            loss = loss_fn(outputs, labels)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n\n            total_predictions += labels.size(0)\n            correct_predictions += predicted.eq(labels).sum().item()\n            num_batches += 1\n\n            if return_confusion_matrix:\n                for pred, label in zip(predicted, labels):\n                    confusion_matrix[pred][label] += 1\n\n    if return_confusion_matrix:\n        return test_loss / num_batches , correct_predictions / total_predictions, confusion_matrix \n    \n    return test_loss / num_batches , correct_predictions / total_predictions \n\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:48:32.551948Z","iopub.status.busy":"2023-04-27T20:48:32.551626Z","iopub.status.idle":"2023-04-27T20:48:32.563826Z","shell.execute_reply":"2023-04-27T20:48:32.562814Z"},"papermill":{"duration":0.018811,"end_time":"2023-04-27T20:48:32.565989","exception":false,"start_time":"2023-04-27T20:48:32.547178","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Define the benchmark ~ dataloader \n\nfrom avalanche.benchmarks.classic.clear import CLEAR\n\n# normalize with the metrics from ImageNet\nnormalize = torchvision.transforms.Normalize(\n  mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n)\ntrain_transform = torchvision.transforms.Compose(\n  [\n    torchvision.transforms.Resize(224),\n    torchvision.transforms.RandomCrop(224),\n    torchvision.transforms.ToTensor(),\n    normalize,\n  ]\n)\ntest_transform = torchvision.transforms.Compose(\n  [\n    torchvision.transforms.Resize(224),\n    torchvision.transforms.CenterCrop(224),\n    torchvision.transforms.ToTensor(),\n    normalize,\n  ]\n)\n\n\nbenchmark = CLEAR(\n  data_name='clear10',\n  evaluation_protocol='iid', # streaming = test on the next task | iid = test on a 30% test split from the current task \n  feature_type=None, # return RGB images, not features extracted by pre-trained models\n  seed=0,\n  train_transform=train_transform,\n  eval_transform=test_transform,\n  dataset_root='/kaggle/input/dl-dataset',\n)\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:48:32.573418Z","iopub.status.busy":"2023-04-27T20:48:32.573141Z","iopub.status.idle":"2023-04-27T20:50:40.872368Z","shell.execute_reply":"2023-04-27T20:50:40.871267Z"},"papermill":{"duration":128.305938,"end_time":"2023-04-27T20:50:40.875064","exception":false,"start_time":"2023-04-27T20:48:32.569126","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title metrics\n\n# intended behavior:\n# def my_metric(batch_logits, labels) -> tensor with the same len as the batch,\n# containing the calculated metric for each sample in the batch, based on the logits and the gt labels\n\ndef margin(batch, labels):\n    '''\n    The margin for a sample is the difference between the logit of the correct class\n    and the other largest logit. For misclassified samples the margin is negative.\n    '''\n    # batch_logits -> (N x num_classes)\n    # labels -> (N,)\n    batch_logits = nn.functional.softmax(batch, dim=1)\n    \n    label_logits = torch.gather(batch_logits, 1, labels.unsqueeze(1)).squeeze()\n    label_logits = label_logits\n    for i in range(labels.shape[0]):\n        batch_logits[i, labels[i]] = 0\n\n        other_logits = torch.max(batch_logits, dim=1)[0]\n\n    margins = label_logits - other_logits\n    return margins.to('cpu') # I don't need this metric to be on the gpu\n\n\ndef entropy(batch, labels):\n    ''' \n    Return a tensor of the same shape as labels, containing the entropy of the logits for each sample \n    '''\n    batch_logits = nn.functional.softmax(batch, dim=1)\n    entropy = -(batch_logits * torch.log(batch_logits)).sum(dim=1) # log or log2\n\n    return entropy.to('cpu')\n\n\ndef el2n(batch, labels, num_classes=11):\n    '''\n    Return a tensor of the same shape as labels, containing the EL2N for the current batch of logits\n    '''\n    batch_logits = nn.functional.softmax(batch, dim=1)\n    one_hot_labels = nn.functional.one_hot(labels, num_classes=num_classes)\n    batch_logits = batch_logits\n\n    x = batch_logits - one_hot_labels\n    el2n = torch.linalg.vector_norm(x, dim=1)\n\n    return el2n.to('cpu')\n\ndef random_sampling(batch, labels):\n    '''\n    Return a tensor of random numbers -> samples will be chosen randomly\n    '''\n    \n    return torch.rand(labels.shape[0])\n    \n\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:50:40.883592Z","iopub.status.busy":"2023-04-27T20:50:40.882994Z","iopub.status.idle":"2023-04-27T20:50:40.893201Z","shell.execute_reply":"2023-04-27T20:50:40.892089Z"},"papermill":{"duration":0.017034,"end_time":"2023-04-27T20:50:40.895687","exception":false,"start_time":"2023-04-27T20:50:40.878653","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title get subset\n\nclass IdxDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, dataset_):\n        self.ds = dataset_\n    \n    def __getitem__(self, index):\n        data, target, _ = self.ds[index] # benchmark datasets also return the task_index\n        \n        return data, target, index\n\n    def __len__(self):\n        return len(self.ds)\n\ndef select_top_samples(net, device, dataset, metric, mode='max', fraction=0.01, offset=0):\n    '''\n    Select top fraction samples from the dataset, based on the metric provided. Use mode='max'\n    if the sample with the highest values should be taken, or 'min' otherwise.\n    fraction - a number between 0.01 and 0.99 (0.1 would be a more practical upper bound)\n    offset - number of top samples to ignore - in case there are misslabeled datapoints\n            - make sure offset + fraction * len(dataset) <= len(dataset)\n    '''\n    metric_scores = torch.full((len(dataset),), -128 if mode=='max' else 128, dtype=torch.float32)\n    idx_dataset = IdxDataset(dataset)\n    sel_loader = DataLoader(idx_dataset, batch_size=128, shuffle=False, num_workers=2)\n\n    with torch.no_grad():\n        for batch, labels, idxs in sel_loader:\n            batch, labels = batch.to(device), labels.to(device)\n            output = net(batch)\n            \n            batch_metrics = metric(output, labels)\n            metric_scores[idxs] = batch_metrics\n\n    sample_args = torch.argsort(metric_scores, descending=(mode=='max')) # get indices that sort the samples\n    \n    num_samples_to_take = int(fraction * len(dataset))\n    selected_samples = sample_args[offset: offset+num_samples_to_take]\n    sampled_subset = torch.utils.data.Subset(dataset, selected_samples)\n    \n    return sampled_subset\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:50:40.903812Z","iopub.status.busy":"2023-04-27T20:50:40.903034Z","iopub.status.idle":"2023-04-27T20:50:40.912716Z","shell.execute_reply":"2023-04-27T20:50:40.911622Z"},"papermill":{"duration":0.016332,"end_time":"2023-04-27T20:50:40.915241","exception":false,"start_time":"2023-04-27T20:50:40.898909","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Initialize model and optimizer\nBATCH_SIZE = 64\nBATCH_SIZE_TEST = 128\nNUM_MAX_EPOCHS_TASK = 40\nNUM_MIN_EPOCHS_TASK = 20\nPATIENCE = 5\nloss_threshold = 0\noptimizer_lr = 1e-2\nmetric_used = random_sampling\nmode_used='max'\nfraction_used = 0.05\noffset_used = 0\ntest_name = 'random_5_3'\n\ntarget_device = 'cpu'\nif torch.cuda.is_available():\n    target_device = 'cuda'\nelse:\n    sys.exit('CUDA not available.')\n\ndevice = torch.device(target_device)\n\nmodel = torchvision.models.resnet18(weights=None, num_classes= 11)\nmodel.to(device)\noptimizer = optim.SGD(model.parameters(), lr=optimizer_lr, momentum=0.9, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_MAX_EPOCHS_TASK, verbose=False)\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:50:40.922966Z","iopub.status.busy":"2023-04-27T20:50:40.922701Z","iopub.status.idle":"2023-04-27T20:50:43.964063Z","shell.execute_reply":"2023-04-27T20:50:43.962938Z"},"papermill":{"duration":3.048553,"end_time":"2023-04-27T20:50:43.967040","exception":false,"start_time":"2023-04-27T20:50:40.918487","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title Iterate over tasks and save metrics\nfrom tqdm import tqdm\n\n\ntrain_accs = np.zeros((10, NUM_MAX_EPOCHS_TASK), dtype=np.float32)\ntrain_losses = np.zeros((10, NUM_MAX_EPOCHS_TASK), dtype=np.float32)\n\ntest_accs = np.zeros((10, NUM_MAX_EPOCHS_TASK), dtype=np.float32)\ntest_losses = np.zeros((10, NUM_MAX_EPOCHS_TASK), dtype=np.float32)\n\naccuracy_matrix = np.zeros((10, 10), dtype=np.float32)\nconfusion_matrices = [] # confusion_matrices[exp, task] is the confusion matrix after experience {exp} on task {task} \nratios_during_training = {} # ratios of neurons not activating during training\n                            # (integer) exp: [ratios] # ratios saved every 5 epochs and once more after the last training epoch on each experience  \nsubsets_memory = []\n\nfor exp_index, (experience, test_experience) in tqdm(enumerate(zip(benchmark.train_stream, benchmark.test_stream))):\n    g = torch.Generator()\n    g.manual_seed(seed)\n\n    train_dataset = experience.dataset\n    # concat the current experience with the saved subsets from previous experiences\n    train_dataset = torch.utils.data.ConcatDataset([train_dataset, *subsets_memory]) \n    print(\"train_dataset length: \", len(train_dataset))\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n        num_workers=2, worker_init_fn=seed_worker, generator=g)\n    test_dataset = test_experience.dataset\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=2)\n    \n    # init for early stopping\n    last_loss = float('inf') \n    anger = 0\n    best_test_acc = 0\n    # ratios list duting training on current experience\n    current_exp_ratios = []\n    # init optimizer lr and the scheduler before every experience\n    print('Optimizer lr:', optimizer.param_groups[0]['lr'])\n    optimizer.param_groups[0]['lr'] = optimizer_lr\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_MAX_EPOCHS_TASK, verbose=False)\n    for epoch in tqdm(range(1, NUM_MAX_EPOCHS_TASK+1)):\n        train_loss, train_acc = train(model, optimizer, criterion, train_loader, device)\n        train_losses[exp_index, epoch-1] = train_loss\n        train_accs[exp_index, epoch-1] = train_acc\n\n        test_loss, test_acc = test(model, criterion, test_loader, device)\n        test_losses[exp_index, epoch-1] = test_loss\n        test_accs[exp_index, epoch-1] = test_acc\n\n        scheduler.step()\n        \n        # save model with the best acc on validation/test\n        if test_acc > best_test_acc:\n            torch.save(model.state_dict(), f'./{test_name}_model_{exp_index}.pt')\n            best_test_acc = test_acc\n        \n        # early stopping criterion - test loss didn't improve by at least {loss_threshold} in the last {PATIENCE} epochs\n        if last_loss - test_loss < loss_threshold:\n            anger += 1\n            if epoch >= NUM_MIN_EPOCHS_TASK and anger >= PATIENCE:\n                break\n        else:\n            anger = 0\n            last_loss = test_loss\n    \n    # load back the weights from the best model\n    model.load_state_dict(torch.load(f'./{test_name}_model_{exp_index}.pt'))\n    \n    exp_conf_matrices = []\n    # test on all the test_tasks for the accuracy matrix\n    for j, exp in tqdm(enumerate(benchmark.test_stream)):\n        test_dataset = exp.dataset\n        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=2)\n\n        test_loss, test_acc, conf_matrix = test(model, criterion, test_loader, device, return_confusion_matrix=True)\n        accuracy_matrix[exp_index, j] = test_acc * 100\n        exp_conf_matrices.append(conf_matrix)\n    \n    confusion_matrices.append(exp_conf_matrices)\n\n    # get subset for the current experience\n    exp_subset = select_top_samples(model, device, experience.dataset, metric_used, mode_used, fraction_used, offset_used)\n    subsets_memory.append(exp_subset)\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T20:50:43.975860Z","iopub.status.busy":"2023-04-27T20:50:43.975551Z","iopub.status.idle":"2023-04-27T22:20:12.777921Z","shell.execute_reply":"2023-04-27T22:20:12.776590Z"},"papermill":{"duration":5368.809626,"end_time":"2023-04-27T22:20:12.780267","exception":false,"start_time":"2023-04-27T20:50:43.970641","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## save acc matrix and train metrics at the end\ntry:\n    with open(f'./{test_name}_acc_matrix.npy', 'wb') as f:\n        np.save(f, accuracy_matrix)\nexcept:\n    print(\"saving acc matrix failed\")\n    print(accuracy_matrix)\n    \ntry:\n    confusion_matrices = np.array(confusion_matrices, dtype=np.int32)\n    with open(f'./{test_name}_conf_matrices.npy', 'wb') as f:\n        np.save(f, confusion_matrices)\nexcept:\n    print(\"saving conf matrices failed\")\n    print(confusion_matrices)\n\ntry:\n    with open(f'./{test_name}_train_accs.npy', 'wb') as f:\n        np.save(f, train_accs)\nexcept:\n    print(\"saving train accs failed\")\n\ntry:\n    with open(f'./{test_name}_train_losses.npy', 'wb') as f:\n        np.save(f, train_losses)\nexcept:\n    print(\"saving train_losses failed\")\n\ntry:\n    with open(f'./{test_name}_test_accs.npy', 'wb') as f:\n        np.save(f, test_accs)\nexcept:\n    print(\"saving test accs failed\")\n    print(test_accs)\n\ntry:\n    with open(f'./{test_name}_test_losses.npy', 'wb') as f:\n        np.save(f, test_losses)\nexcept:\n    print(\"saving test losses failed\")\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T22:20:12.888323Z","iopub.status.busy":"2023-04-27T22:20:12.887957Z","iopub.status.idle":"2023-04-27T22:20:12.906184Z","shell.execute_reply":"2023-04-27T22:20:12.905117Z"},"papermill":{"duration":0.074802,"end_time":"2023-04-27T22:20:12.908657","exception":false,"start_time":"2023-04-27T22:20:12.833855","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\ns = sns.heatmap(accuracy_matrix, cmap='Blues', annot=True, \n    xticklabels=[f'Test {t}' for t in range(1,11)],\n    yticklabels=[f'Time {t}' for t in range(1,11)],\n    square=True, fmt='.1f'\n)\n\nplt.savefig(f'./{test_name}_acc_matrix.jpg', bbox_inches='tight')\nplt.show()\n","metadata":{"execution":{"iopub.execute_input":"2023-04-27T22:20:13.019633Z","iopub.status.busy":"2023-04-27T22:20:13.017577Z","iopub.status.idle":"2023-04-27T22:20:14.591215Z","shell.execute_reply":"2023-04-27T22:20:14.590160Z"},"papermill":{"duration":1.630959,"end_time":"2023-04-27T22:20:14.593659","exception":false,"start_time":"2023-04-27T22:20:12.962700","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.054253,"end_time":"2023-04-27T22:20:14.702979","exception":false,"start_time":"2023-04-27T22:20:14.648726","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}